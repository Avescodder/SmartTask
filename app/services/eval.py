
from typing import Dict
from app.services.rag_service import RAGService
from app.database import get_db_context
import asyncio
from app.utils.logger import logger


class RAGEvaluator:
    """Evaluate RAG system quality based on ACTUAL documents"""
    
    def __init__(self):
        self.test_questions = [
            {
                "question": "ĞšĞ°Ğº ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ?",
                "expected_keywords": ["Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°", "Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ", "+", "Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ"],
                "category": "task_management"
            },
            
            {
                "question": "Ğ“Ğ´Ğµ Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ?",
                "expected_keywords": ["aws", "Ñ„Ñ€Ğ°Ğ½ĞºÑ„ÑƒÑ€Ñ‚", "Ğ³ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ"],
                "category": "security"
            },
            
            {
                "question": "ĞšĞ°ĞºĞ¸Ğµ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ?",
                "expected_keywords": ["slack", "github", "google"],
                "category": "integrations"
            },
            
            {
                "question": "ĞšĞ°Ğº Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ‡ĞµÑ€ĞµĞ· API?",
                "expected_keywords": ["get", "/tasks", "api"],
                "category": "api"
            },
            
            {
                "question": "ĞšĞ°Ğº ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ¼?",
                "expected_keywords": ["kanban", "Ğ´Ğ¾ÑĞºĞ°", "Ğ¿ĞµÑ€ĞµÑ‚Ğ°ÑĞºĞ¸Ğ²Ğ°"],
                "category": "project_management"
            },
            
            {
                "question": "ĞšĞ°ĞºĞ¾Ğµ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ?",
                "expected_keywords": ["aes", "256", "ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½"],
                "category": "security"
            },
            
            {
                "question": "ĞšĞ°ĞºĞ¸Ğµ ĞµÑÑ‚ÑŒ Ñ‚Ğ°Ñ€Ğ¸Ñ„Ğ½Ñ‹Ğµ Ğ¿Ğ»Ğ°Ğ½Ñ‹?",
                "expected_keywords": ["free", "pro", "enterprise"],
                "category": "pricing"
            },
            
            {
                "question": "Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´ÑÑ‚ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ?",
                "expected_keywords": ["email", "ÑĞ¿Ğ°Ğ¼", "Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹Ğº", "ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½"],
                "category": "troubleshooting"
            },
            
            {
                "question": "ĞšĞ°ĞºĞ¾Ğ¹ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ°?",
                "expected_keywords": ["50", "Ğ¼Ğ±", "Ñ„Ğ°Ğ¹Ğ»"],
                "category": "features"
            },
        ]
    
    async def evaluate(self) -> Dict:
        """Run evaluation on test questions"""
        results = {
            "total": len(self.test_questions),
            "passed": 0,
            "failed": 0,
            "by_category": {},
            "details": []
        }
        
        with get_db_context() as db:
            rag = RAGService(db)
            
            for test_case in self.test_questions:
                question = test_case["question"]
                expected_keywords = test_case["expected_keywords"]
                category = test_case["category"]
                
                try:
                    response = await rag.answer_question(question)
                    answer = response.answer.lower()
                    
                    found_keywords = [
                        kw for kw in expected_keywords 
                        if kw.lower() in answer
                    ]
                    
                    threshold = len(expected_keywords) * 0.4
                    passed = len(found_keywords) >= threshold
                    
                    if passed:
                        results["passed"] += 1
                    else:
                        results["failed"] += 1
                    
                    if category not in results["by_category"]:
                        results["by_category"][category] = {"passed": 0, "total": 0}
                    
                    results["by_category"][category]["total"] += 1
                    if passed:
                        results["by_category"][category]["passed"] += 1
                    
                    results["details"].append({
                        "question": question,
                        "category": category,
                        "passed": passed,
                        "found_keywords": found_keywords,
                        "expected_keywords": expected_keywords,
                        "keyword_match_rate": len(found_keywords) / len(expected_keywords),
                        "answer_preview": answer[:200] + "..." if len(answer) > 200 else answer,
                        "response_time": response.response_time,
                        "tokens_used": response.tokens_used,
                        "sources_count": len(response.sources)
                    })
                
                except Exception as e:
                    logger.error(f"Error evaluating question '{question}': {e}")
                    results["failed"] += 1
                    results["details"].append({
                        "question": question,
                        "category": category,
                        "passed": False,
                        "error": str(e)
                    })
        
        results["accuracy"] = results["passed"] / results["total"] if results["total"] > 0 else 0
        
        for category, stats in results["by_category"].items():
            stats["accuracy"] = stats["passed"] / stats["total"] if stats["total"] > 0 else 0
        
        return results


async def run_eval():
    """Run and display evaluation results"""
    evaluator = RAGEvaluator()
    results = await evaluator.evaluate()
    
    print("\n" + "="*70)
    print("ğŸ“Š RAG System Evaluation Results")
    print("="*70)
    print(f"Total tests: {results['total']}")
    print(f"Passed: {results['passed']}")
    print(f"Failed: {results['failed']}")
    print(f"Overall Accuracy: {results['accuracy']:.1%}")
    print("="*70)
    
    print("\nğŸ“ Results by Category:")
    for category, stats in sorted(results['by_category'].items()):
        passed = stats['passed']
        total = stats['total']
        accuracy = stats['accuracy']
        
        emoji = "âœ…" if accuracy >= 0.7 else "âš ï¸" if accuracy >= 0.5 else "âŒ"
        print(f"  {emoji} {category.upper()}:")
        print(f"      Passed: {passed}/{total} ({accuracy:.1%})")
    
    print("\nğŸ“ Detailed Results:")
    print("-"*70)
    
    for detail in results['details']:
        status = "âœ… PASS" if detail['passed'] else "âŒ FAIL"
        print(f"\n{status} [{detail['category']}]")
        print(f"Question: {detail['question']}")
        
        if 'error' in detail:
            print(f"Error: {detail['error']}")
        else:
            match_rate = detail.get('keyword_match_rate', 0)
            print(f"Keyword Match: {match_rate:.1%}")
            print(f"Found: {detail['found_keywords']}")
            print(f"Expected: {detail['expected_keywords']}")
            print(f"Sources: {detail.get('sources_count', 0)} | "
                  f"Time: {detail.get('response_time', 0):.2f}s | "
                  f"Tokens: {detail.get('tokens_used', 0)}")
    
    print("\n" + "="*70)

    if results['accuracy'] < 0.7:
        print("\nğŸ’¡ Recommendations:")
        print("  1. Check if documents are loaded: docker compose logs api | grep 'Loaded'")
        print("  2. Increase top_k in config.py (try 5 or 7)")
        print("  3. Lower similarity_threshold (try 0.2)")
        print("  4. Use better model: OPENAI_MODEL=gpt-4o-mini")
    elif results['accuracy'] >= 0.7:
        print("\nğŸ‰ Good results! System is working well.")
    
    print("="*70 + "\n")
    
    return results


if __name__ == "__main__":
    asyncio.run(run_eval())